# Awesome-Model-Quantization-and-Compression 

Collect some spiking neural network papers & codes.  (**Actively keep updating**)

If you own or find some overlooked SNN papers, you can add them to this document by pull request. 

## News

[2024.12.24] Update Quantization-related papers in NeurIPS 2024 (21 papers).


## Papers
### 2024

**NeurIPS, ACM MM, ECCV, AAAI, ICLR, CVPR, ICML, IJCAI**
- Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models (**NeurIPS 2024**). [[paper](https://openreview.net/forum?id=QAiKLaCrKj)]
- BitsFusion: 1.99 bits Weight Quantization of Diffusion Model (**NeurIPS 2024**). [[paper](https://openreview.net/forum?id=QAiKLaCrKj)]
- SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training (**NeurIPS 2024**). [[paper](https://openreview.net/forum?id=PEEqnXlSCk)]
- QTIP: Quantization with Trellises and Incoherence Processing (**NeurIPS 2024**). [[paper](https://openreview.net/pdf?id=7sdkLVuYCU)]  [[code](https://github.com/Cornell-RelaxML/qtip)]
- Generalizing CNNs to graphs with learnable neighborhood quantization (**NeurIPS 2024**). [[paper](https://openreview.net/forum?id=dYIqAZXQNV)]  [[code](https://github.com/Grosenick-Lab-Cornell/QuantNets)]
- Vector Quantization Prompting for Continual Learning (**NeurIPS 2024**). [[paper](https://openreview.net/forum?id=ACCqGLviig)]  [[code](https://github.com/jiaolifengmi/VQ-Prompt)]
- 2DQuant: Low-bit Post-Training Quantization for Image Super-Resolution. [[paper](https://openreview.net/forum?id=ADJASE9uQ2)]  [[code](https://github.com/Kai-Liu001/2DQuant)]
- KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization. [[paper](https://openreview.net/pdf?id=pNnvzQsS4P)]
- QBB: Quantization with Binary Bases for LLMs. [[paper](https://openreview.net/pdf?id=Kw6MRGFx0R)]
- Autoregressive Image Generation without Vector Quantization. [[paper](https://openreview.net/forum?id=VNBIF0gmkb)]  [[code](https://github.com/LTH14/mar)]
- Exploiting LLM Quantization. [[paper](https://openreview.net/forum?id=ISa7mMe7Vg)]  [[code](https://github.com/eth-sri/llm-quantization-attack)]
- Optimal and Approximate Adaptive Stochastic Quantization. [[paper](https://openreview.net/forum?id=8ZLL6mu2qC)]  [[code](https://github.com/ranbenbasat/QUIVER)]
- PTQ4DiT: Post-training Quantization for Diffusion Transformers. [[paper](https://openreview.net/forum?id=NLmAGkN6nn)]  [[code](https://github.com/adreamwu/PTQ4DiT)]
- Efficient Multi-task LLM Quantization and Serving for Multiple LoRA Adapters. [[paper](https://openreview.net/forum?id=HfpV6u0kbX)]
- ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification. [[paper](https://openreview.net/forum?id=5t4ZAkPiJs)] [[code](https://github.com/ThisisBillhe/ZipCache/)]
- VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization. [[paper](https://openreview.net/forum?id=bKuxygBW2Y)]
- MagR: Weight Magnitude Reduction for Enhancing Post-Training Quantization. [[paper](https://openreview.net/forum?id=UARTFgkTqW)] [[code](https://github.com/AozhongZhang/MagR)]
- Q-VLM: Post-training Quantization for Large Vision-Language Models. [[paper](https://openreview.net/forum?id=gxMfNArldP)] [[code](https://github.com/ChangyuanWang17/QVLM)]
- Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers. [[paper](https://openreview.net/forum?id=6uv9ViIoMj)]
- BiDM: Pushing the Limit of Quantization for Diffusion Models. [[paper](https://openreview.net/forum?id=oWAItGB8LJ)] [[code](https://github.com/Xingyu-Zheng/BiDM)]












